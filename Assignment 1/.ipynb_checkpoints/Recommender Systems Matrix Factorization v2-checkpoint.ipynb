{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recommender Systems  Matrix Factorization \n",
    "## Introduction\n",
    "In this task, we will be working on the MovieLens 1M dataset which can be fetched from moivelens . This set contains about 1.000.000 ratings given to about 4.000 movies by about 6.000 users. Our task adopted Matrix Factorization Algorithm in Python and estimated the accuracy with the Root Mean Squared Error, RMSE, and the Mean Absolute Error, MAE.\n",
    "\n",
    "To make sure that the results are reliable, 5-fold cross- validation is used.\n",
    "\n",
    "## Gradient Descend\n",
    "This was described in the paper gravity-Tikk.pdf (the beginning of section 3.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import random\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "from math import sqrt\n",
    "\n",
    "#Import libs to plot the training process\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#Set the random seed to make the experiment repeatable\n",
    "np.random.seed(2019)\n",
    "random.seed(2019)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data\n",
    "The CSV file ratings.csv contains 100836 ratings created by 610 users about 9742 movies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Define the file path\n",
    "file_path = '../data/ratings.csv'#\"./ml-latest-small/ratings.csv\" \n",
    "df_ratings = pd.read_csv(file_path, header=0, names=['userId', 'movieId', 'rating'], index_col=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Renumbering user and movie IDs\n",
    "uniqueMovieIds = df_ratings.movieId.unique() #Obtain the unique movie Ids\n",
    "uniqueUserIds = df_ratings.userId.unique() #Obtain the unique user Ids\n",
    "\n",
    "#Create New movieIds according to unique movie Ids\n",
    "newMovieIds = [np.where(uniqueMovieIds==x)[0][0] for x in df_ratings['movieId'].tolist()]\n",
    "newMovieIds = np.array(newMovieIds)\n",
    "\n",
    "#Create New userIds according to unique user Ids\n",
    "newUserIds = [np.where(uniqueUserIds==x)[0][0] for x in df_ratings['userId'].tolist()]\n",
    "newUserIds = np.array(newUserIds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Add new movieIds and new userIds to the dataframe\n",
    "df_ratings['newMovieId'] = newMovieIds\n",
    "df_ratings['newUserId'] = newUserIds\n",
    "\n",
    "#Reconstruct the dataframe\n",
    "df_ratings = df_ratings[[\"newUserId\",\"newMovieId\",\"rating\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(610, 9724)\n"
     ]
    }
   ],
   "source": [
    "#Construct The Rating Matrix acorting to the new ids\n",
    "num_users = df_ratings['newUserId'].max()+1  #There are 610 users\n",
    "num_movies = df_ratings['newMovieId'].max()+1 #The Max Value of movieId\n",
    "\n",
    "ratings = np.zeros((num_users , num_movies))\n",
    "\n",
    "print(ratings.shape)\n",
    "\n",
    "for i in range(df_ratings.shape[0]):\n",
    "    ratings[df_ratings.loc[i, 'newUserId']][df_ratings.loc[i,'newMovieId']] = df_ratings.loc[i, 'rating']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class MatrixFactorization():\n",
    "    def __init__( self, R=ratings, df=df_ratings, K=20, lr=0.001, rp=0.01, itr= 3, nfolds=5): \n",
    "        #change itr and set thresholds\n",
    "        \"\"\"\n",
    "        Arguments/Hyperparamters\n",
    "        -R: user-movie: rating matrix\n",
    "        -K: number of latent dimensions of user & movie vectors\n",
    "        -lr: learning rate\n",
    "        -rp: regularization parametre\n",
    "        -itr: number of iterations\n",
    "        \"\"\"     \n",
    "        self.R=R\n",
    "        self.df = df\n",
    "        self.num_users, self.num_movies = R.shape\n",
    "        self.K = K\n",
    "        self.lr = lr\n",
    "        self.rp = rp\n",
    "        self.itr = itr\n",
    "        self.nfolds = nfolds\n",
    "              \n",
    "    def train_n_times(self):\n",
    "        # set up the empty result list\n",
    "        err=[]\n",
    "        kf = KFold(n_splits= self.nfolds, shuffle=True)\n",
    "        n_t = 1\n",
    "        for train_index, test_index in kf.split(self.df):\n",
    "            print('Training No.', n_t)\n",
    "            n_t += 1\n",
    "            training_set, test_set = self.df.iloc[train_index], self.df.iloc[test_index]\n",
    "            self.check_matrix = np.zeros(self.R.shape)\n",
    "            training_process = self.train(training_set, test_set)\n",
    "            err.append(training_process )\n",
    "        return (err)\n",
    "            \n",
    "    def gradient_descent(self, training):\n",
    "        #Update the parametres of user&movie matrix in one iteration\n",
    "        for u, m, r in training:\n",
    "            if r:\n",
    "                \n",
    "                error = r - self.predict_um(u,m)\n",
    "                self.U[u] += self.lr*(error*self.M[m]-self.rp*self.U[u])\n",
    "                self.M[m] += self.lr*(error*self.U[u] - self.rp*self.M[m])\n",
    "\n",
    "    def train(self, training_set, test_set):\n",
    "        #Initialize user & movie matrices \n",
    "        self.U = np.random.normal(scale=1./self.K, size=(self.num_users, self.K))\n",
    "        self.M = np.random.normal(scale=1./self.K, size=(self.num_movies, self.K))\n",
    "        \n",
    "        #Perform stochastic gradient descent \n",
    "        training_process = []\n",
    "        training = training_set.as_matrix().astype(int)\n",
    "        test = test_set.as_matrix().astype(int)\n",
    "        for i in range(self.itr):\n",
    "            self.gradient_descent(training)\n",
    "            mse_training = self.calculate_mse(training)\n",
    "            mse_test = self.calculate_mse(test, mode=\"test\")\n",
    "            training_process.append((i, mse_training, mse_test))\n",
    "        \n",
    "            print(\"Iteration: %d; mse_traing: %.4f; mse_test: %.4f\"%(i+1, mse_training, mse_test))\n",
    "            \n",
    "        iterations = [i for i, mse_training, mse_test in training_process]\n",
    "        mse_training = [mse_training for i, mse_training, mse_test in training_process]\n",
    "        mse_test = [mse_test for i, mse_training, mse_test in training_process]\n",
    "        plt.figure(figsize=(16, 4))\n",
    "        plt.title(\"Training Error And Validation Error\")\n",
    "        plt.plot(iterations, mse_training, color='blue', label = 'training error')\n",
    "        plt.plot(iterations, mse_test, color='orange', label='validation error')\n",
    "        plt.xticks(iterations, iterations)\n",
    "        plt.xlabel(\"Iterations\")\n",
    "        plt.ylabel(\"Mean Square Error\")\n",
    "        plt.legend()\n",
    "        plt.grid(axis=\"y\")\n",
    "        #plt.show()\n",
    "        return training_process\n",
    "            \n",
    "            \n",
    "    def round_of_rating(self, R):\n",
    "        R[np.where(R<1)]=1\n",
    "        R[np.where(R>5)] = 5\n",
    "        \n",
    "        matrixRound = np.vectorize(round) #Vectorize the round function\n",
    "        return matrixRound(R*2)/2 # Round off the rating to nearest 0.5\n",
    "    \n",
    "    \n",
    "    def predictAll(self):\n",
    "        #Predict All the Ratings, return a full rating matrix\n",
    "        predictions = self.U.dot(self.M.T)\n",
    "        return self.round_of_rating(predictions)       \n",
    "    \n",
    "    def predict_um(self, u, m, mode=\"train\"):\n",
    "        #Predict the rating of user u to movie m\n",
    "        \n",
    "        if mode==\"test\":\n",
    "            if sum(self.check_matrix[u])==0 or sum(self.check_matrix.T[m])==0:\n",
    "            #Data not present in training_set\n",
    "                \n",
    "                return self.check_matrix.mean()\n",
    "            \n",
    "            return self.U[u,:].dot(self.M[m].T)\n",
    "            \n",
    "        \n",
    "        prediction = self.U[u,:].dot(self.M[m].T)\n",
    "        self.check_matrix[u][m]=prediction\n",
    "        return prediction\n",
    "    \n",
    "    def calculate_mse(self, d, mode=\"training\"):\n",
    "        #Calculate mse for Training/Testing set\n",
    "        #train_pred['diff'] = (d.rating - self.predictALL))**2\n",
    "        #err_train.append(np.sqrt(train_pred['diff'].mean()))\n",
    "        num_of_d = len(d)\n",
    "        error = 0\n",
    "        \n",
    "        for i, j, r in d:\n",
    "            prediction = self.predict_um(i,j, mode)\n",
    "            error += (prediction - r )**2\n",
    "            \n",
    "        error = error/num_of_d\n",
    "        return error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training No. 1\n",
      "Iteration: 1; mse_traing: 12.3898; mse_test: 12.5065\n",
      "Iteration: 2; mse_traing: 12.3870; mse_test: 12.5062\n",
      "Iteration: 3; mse_traing: 12.3835; mse_test: 12.5052\n",
      "Training No. 2\n",
      "Iteration: 1; mse_traing: 12.4263; mse_test: 12.3559\n",
      "Iteration: 2; mse_traing: 12.4230; mse_test: 12.3552\n",
      "Iteration: 3; mse_traing: 12.4181; mse_test: 12.3530\n",
      "Training No. 3\n",
      "Iteration: 1; mse_traing: 12.4106; mse_test: 12.4224\n",
      "Iteration: 2; mse_traing: 12.4080; mse_test: 12.4224\n",
      "Iteration: 3; mse_traing: 12.4048; mse_test: 12.4220\n",
      "Training No. 4\n",
      "Iteration: 1; mse_traing: 12.4196; mse_test: 12.3850\n",
      "Iteration: 2; mse_traing: 12.4167; mse_test: 12.3846\n",
      "Iteration: 3; mse_traing: 12.4126; mse_test: 12.3832\n",
      "Training No. 5\n",
      "Iteration: 1; mse_traing: 12.4152; mse_test: 12.4039\n",
      "Iteration: 2; mse_traing: 12.4123; mse_test: 12.4037\n",
      "Iteration: 3; mse_traing: 12.4085; mse_test: 12.4026\n"
     ]
    }
   ],
   "source": [
    "mf = MatrixFactorization()\n",
    "err = mf.train_n_times()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[(0, 12.389827347718743, 12.506452556030455),\n",
       "  (1, 12.387034053493505, 12.506155531832315),\n",
       "  (2, 12.383452980048187, 12.505151737374339)],\n",
       " [(0, 12.4263465377191, 12.355946520684416),\n",
       "  (1, 12.423019708445315, 12.35520336894954),\n",
       "  (2, 12.418126294231769, 12.35303623627073)],\n",
       " [(0, 12.410569216632254, 12.42238758169633),\n",
       "  (1, 12.407980262434469, 12.422399365461212),\n",
       "  (2, 12.404842788121064, 12.421951618919449)],\n",
       " [(0, 12.419627184890595, 12.384964912695875),\n",
       "  (1, 12.416665119182433, 12.384578381817704),\n",
       "  (2, 12.412589877519785, 12.38318516462108)],\n",
       " [(0, 12.415221238996185, 12.403890135271178),\n",
       "  (1, 12.412344625211947, 12.40366331544816),\n",
       "  (2, 12.40853027071433, 12.402620035562553)]]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result = np.mean(err, axis = 0)[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For the MF with GD \n",
      "Mean error on TRAIN: 12.405508442127026\n",
      "Mean error on  TEST: 12.41318895854963\n"
     ]
    }
   ],
   "source": [
    "#print the final conclusion:\n",
    "print(\"For the MF with GD \")\n",
    "print(\"Mean error on TRAIN: \" + str(result[1]))\n",
    "print(\"Mean error on  TEST: \" + str(result[2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## MF with ALS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class MatrixFactorizationV3(MatrixFactorizationV2):\n",
    "    def ALS(self):       \n",
    "        for u in range(self.U.shape[0]):\n",
    "            print(\"userId: \",u)\n",
    "            training_u = [e for e in self.training_set if e[0]==u]\n",
    "            movieIds = [e[1] for e in training_u]\n",
    "            movies = self.M[movieIds]\n",
    "            \n",
    "            rating_indices = list(zip(*training_u))\n",
    "            ratings = self.R[rating_indices]\n",
    "            \n",
    "            weighted_sum = self.calculate_weighted_sum(movies, ratings)\n",
    "            \n",
    "            outer = np.zeros((self.K, self.K))\n",
    "            for movie in movies:\n",
    "                outer = outer+np.outer(movie.T, movie)\n",
    "                \n",
    "            outer = outer +self.rp*np.identity(self.K)\n",
    "            self.U[u] = inv(outer)@weighted_sum\n",
    "            \n",
    "        for m in range(self.M.shape[0]):\n",
    "            print(\"movieId: \",m )\n",
    "            training_m = [e for e in self.training_set if e[1]==m]\n",
    "            userIds = [e[0] for e in training_m]\n",
    "            users = self.U[userIds]\n",
    "            \n",
    "            rating_indices = list(zip(*training_m))\n",
    "            ratings = self.R[rating_indices]\n",
    "            \n",
    "            weighted_sum = self.calculate_weighted_sum(users, ratings)\n",
    "            \n",
    "            outer = np.zeros((self.K, self.K))\n",
    "            for user in users:\n",
    "                outer = outer+np.outer(user.T, user)\n",
    "                \n",
    "            outer=outer+self.rp*np.identity(self.K)\n",
    "            self.M[m] = inv(outer)@weighted_sum\n",
    "            \n",
    "            \n",
    "    def calculate_weighted_sum(self, matrix, weights):\n",
    "        if len(matrix)==1:\n",
    "            return matrix[0]*weights[0]\n",
    "        \n",
    "        return matrix[0]*weights[0]+self.calculate_weighted_sum(matrix[1:], weights[1:])\n",
    "    \n",
    "    \n",
    "    def train(self, training_time=1):\n",
    "        #Initialize user & movie matrices \n",
    "        self.U = np.random.normal(scale=1./self.K, size=(self.num_users, self.K))\n",
    "        self.M = np.random.normal(scale=1./self.K, size=(self.num_movies, self.K))\n",
    "        \n",
    "        #Create a list of training samples\n",
    "        #self.samples = list(self.sampling)\n",
    "        \n",
    "        #Perform stochastic gradient descent \n",
    "        training_process = []\n",
    "        for i in range(self.itr):\n",
    "           \n",
    "            self.ALS()\n",
    "            mse_training = self.calculate_mse(samples=self.training_set)\n",
    "            mse_test = self.calculate_mse(samples=self.test_set)\n",
    "            training_process.append((i, mse_training, mse_test))\n",
    "        \n",
    "            print(\"Iteration: %d; mse_traing: %.4f; mse_test: %.4f\"%(i+1, mse_training, mse_test))\n",
    "            \n",
    "        iterations = [i for i, mse_training, mse_test in training_process]\n",
    "        mse_training = [mse_training for i, mse_training, mse_test in training_process]\n",
    "        mse_test = [mse_test for i, mse_training, mse_test in training_process]\n",
    "        plt.figure(figsize=(16, 4))\n",
    "        plt.title(\"Training Error And Validation Error for Training %d\"%(training_time))\n",
    "        plt.plot(iterations, mse_training, color='blue', label = 'training error')\n",
    "        plt.plot(iterations, mse_test, '.', color='black', label='validation error')\n",
    "        plt.xticks(iterations, iterations)\n",
    "        plt.xlabel(\"Iterations\")\n",
    "        plt.ylabel(\"Mean Square Error\")\n",
    "        plt.legend()\n",
    "        plt.grid(axis=\"y\")\n",
    "    \n",
    "    \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=ratings\n",
    "num_features= 30\n",
    "lmda = 0.01\n",
    "\n",
    "U = np.random.normal(scale=1./30, size=(num_users,num_features))\n",
    "M = np.random.normal(scale=1./30, size=(num_movies,num_features))\n",
    "U[:,0] = np.mean(r_mat, axis = 1)\n",
    "M[:,0] = np.mean(r_mat, axis = 0)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "for u in range(num_users):\n",
    "    vec = X[u,:].nonzero()[0]\n",
    "    MI = M[vec,:]\n",
    "    n = max(len(vec),1)\n",
    "    A = np.dot(MI.T,MI) + lmda*n*np.eye(num_features)\n",
    "    V = np.dot(MI.T,X[u,vec])\n",
    "    U[u,:] = np.linalg.solve(A,V)\n",
    "        \n",
    "for m in range(num_movies):\n",
    "    vec = X[:,m].nonzero()[0]\n",
    "    UI = U[vec,:]\n",
    "    n = max(len(vec),1)\n",
    "    A = np.dot(UI.T,UI) + lmda*n*np.eye(num_features)\n",
    "    V = np.dot(UI.T,X[vec,m])\n",
    "    M[m,:] = np.linalg.solve(A,V)\n",
    "        \n",
    "pred = np.dot(U,M.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[11.00111659,  5.83922018,  8.49458805, ...,  8.96107699,\n",
       "        10.45458982, 10.45458982],\n",
       "       [10.70603268,  2.9157308 ,  9.1484237 , ...,  6.94782112,\n",
       "         8.1057913 ,  8.1057913 ],\n",
       "       [ 7.5006725 ,  2.73303803,  7.32590033, ...,  2.61685728,\n",
       "         3.05300016,  3.05300016],\n",
       "       ...,\n",
       "       [ 3.06061084,  1.47973045,  3.46645412, ...,  2.25243167,\n",
       "         2.62783695,  2.62783695],\n",
       "       [ 3.92444329,  4.05969803,  2.77228623, ...,  5.00310253,\n",
       "         5.83695296,  5.83695296],\n",
       "       [ 2.98637722,  2.8167656 ,  2.81352529, ...,  2.98961347,\n",
       "         3.48788238,  3.48788238]])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec = X[1,:].nonzero()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "MI = M[vec,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(29, 30)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MI.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(MI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30, 30)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.dot(MI.T,MI).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n = max(len(vec),1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = lmda*n*np.eye(num_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30, 30)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2.74816488e+02, -1.73014485e+01,  3.73519954e+00,  4.58754519e+00,\n",
       "       -3.92418684e+00, -1.14276615e+01,  7.44189647e+00,  2.33835722e+00,\n",
       "        1.86372317e+00,  2.40124234e+00, -1.29004363e+01,  1.52248368e-01,\n",
       "       -4.69187155e+00, -1.03098121e+01,  1.14965007e+01, -4.06114255e+00,\n",
       "        2.19929965e+01,  6.07534569e+00, -1.51846538e+01, -1.80145790e+01,\n",
       "       -1.65120020e+01,  5.87314644e+00, -4.05542434e+00, -1.54912875e+01,\n",
       "       -7.22002495e+00, -1.80928491e+01,  1.40070197e+01, -2.70462019e+01,\n",
       "        1.64958127e+01,  1.61422005e+00])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.dot(MI.T,X[u,X[1,:].nonzero()[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30,)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z = np.dot(MI.T,X[1,vec])\n",
    "z.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30, 29)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MI.T.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(29,)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[1,vec].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
