{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recommender Systems  Matrix Factorization \n",
    "## Introduction\n",
    "In this task, we implemented a Recommender Model based on **Matrix Factorization** algorithm. This model is used to recommend movies to users based on historical ratings data. In next sections we will discuss the dataset we used, approaches of Data Exploration, Data Preprocessing, Implementation and Optimization of the Model, and Experiments and Results.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import random\n",
    "import sys\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "from math import sqrt\n",
    "\n",
    "#Import libs to plot the training process\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Exploration\n",
    "The data set we used in this experiment is the MovieLens 1M dataset. Each line of this file below the header represents one rating of one movie(represented by movieId) by one user(represented by userId) and its timestamp. To make things easier, we only use the 3 columns: userId, movieId and rating.\n",
    "\n",
    "The purpose of Initial Data Analysis is to understand what is in a dataset and the characteristics of the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the Ratings File\n",
    "fname = '../data/ratings.dat'\n",
    "data = np.genfromtxt(fname, dtype={'names': ('userId', 'movieId', 'rating'),\n",
    "                     'formats': ('i4', 'i4', 'i1')}, delimiter=\"::\")\n",
    "\n",
    "df_ratings = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean of the ratings is about 3.581564453029317\n"
     ]
    }
   ],
   "source": [
    "# The average rating in the dataset\n",
    "print('The mean of the ratings is about', df_ratings.rating.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jeremydai/anaconda/lib/python3.5/site-packages/matplotlib/axes/_axes.py:6462: UserWarning: The 'normed' kwarg is deprecated, and has been replaced by the 'density' kwarg.\n",
      "  warnings.warn(\"The 'normed' kwarg is deprecated, and has been \"\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZsAAAEWCAYAAACwtjr+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ndv8fTmL5y/eU/swAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Show distribution of ratings\n",
    "data = df_ratings.rating.tolist()\n",
    "\n",
    "plt.title(\"Distribution of Ratings\")\n",
    "plt.hist(data, bins=10, normed=0, facecolor=\"blue\", edgecolor='black', alpha=0.7)\n",
    "plt.xlabel(\"rating\")\n",
    "plt.ylabel(\"frequency\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Range of userId:  [ 1 , 6040 ]\n",
      "Number of userId:  6040\n",
      "Range of movieId:  [ 1 , 3952 ]\n",
      "Number of movieId:  3706\n"
     ]
    }
   ],
   "source": [
    "# The gap in the numbering \n",
    "print(\"Range of userId: \", \"[\",df_ratings.userId.min(), \",\",df_ratings.userId.max(), \"]\")\n",
    "print(\"Number of userId: \", len(df_ratings.userId.unique()))\n",
    "\n",
    "print(\"Range of movieId: \", \"[\", df_ratings.movieId.min(), \",\", df_ratings.movieId.max(), \"]\")\n",
    "print(\"Number of movieId: \", len(df_ratings.movieId.unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a gap in the numbering of movieIds, which will be fixed in the following section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing\n",
    "The purpose of data preprocessing is to fix the gap of the numbering of the original movieId."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for movie ids\n",
    "uniqueIds = df_ratings['movieId'].unique()\n",
    "# use a dictionary to map the data\n",
    "dic = {v: k for k, v in enumerate(uniqueIds)}\n",
    "df_ratings['movieId']  = df_ratings['movieId'].map(lambda x:dic[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for user ids\n",
    "df_ratings.loc[df_ratings['userId'] == 6040,'userId'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6040, 3706)\n"
     ]
    }
   ],
   "source": [
    "# Construct The Rating Matrix acorting to the new ids\n",
    "num_users = df_ratings['userId'].max()+1  \n",
    "num_movies = df_ratings['movieId'].max()+1 \n",
    "ratings = np.zeros((num_users , num_movies))\n",
    "print(ratings.shape) #Show the shape of the rating matrix\n",
    "for i in range(df_ratings.shape[0]):\n",
    "    ratings[df_ratings.loc[i, 'userId']][df_ratings.loc[i,'movieId']] = df_ratings.loc[i, 'rating']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The density of rating matrix:  0.044683625622312845\n"
     ]
    }
   ],
   "source": [
    "# Calculate the density of the matrix\n",
    "density = len(np.nonzero(ratings)[0])/(ratings.shape[0]*ratings.shape[1])\n",
    "print(\"The density of rating matrix: \", density)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The density of the rating matrix is about 0.04; it is still very sparse because most users only reviewed few movies compared with the large number of movies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algorithm for Recommandation\n",
    "We used **Matrix Factorization** for the recommender system. The algorithm attemps to decompose the rating matrix $R$ into the product of 2 lower dimensionality matrices U and M,  in which the users and items are represented in a lower dimensional latent space(K-dimensional Vector).  During the training process, the algorithm will try to minimize the loss function, which is presented by following formula:\n",
    "<center>$||R_{m,n}- U_{m,k}\\times M_{n,k}~T||^2+\\lambda (||U_{m, k}||^2 + ||M_{n, k}||^2)$\n",
    "    \n",
    "**Gradient Descent** and **Alternating Least Square(ALS)** is used to minimize the loss function.\n",
    "\n",
    "After training the parametres of the K-dimensional vectors of users and movies, the rating of movie m given by user u will be the dot product of the user and movie vectors: $r_{u,m} = u\\cdot m$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross Validation and Evaluation \n",
    "**5-fold** cross validation[6] is applied in our experiment to monitor the training process; i.e. We splitted the data into 5 non-overlapping parts and developed 5 same models; each model will choose one part as test set and the remaining 4 as training set. Mean Squared Error(mse) is used to evaluate the models. The final results will be the average mse of the 5 models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Missing Ids in the test dataset\n",
    "During the test of a model, there might be some userIds and movieIds which are present in test set but not present in the training set. Because the parametres of the vectors of these users or movies are not trained before, it is unreliable to use the dot product of their vectors to calculate the ratings.\n",
    "\n",
    "We considered to check which Ids are missing in the training set after splitting the dataset into training set and test set and add some samples from test set to the training set. It seems that this method worked well but it can cause **Data Leakage**[5]; i.e. **Information from outside the training set is used to create the model, which can cause one to create overly optimistic if not completely invalid predictive models.**\n",
    "\n",
    "Instead, we will use the mean value for smoothing, i.e. we will treat the mean of all ratings in the training set as the rating of movie m by user u if u or m not present in the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code implementing the Matrix Factorization model is listed below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#MatrixFactorization Model\n",
    "'''\n",
    "1. Start Matrix Factorization algorithm by instantiating an instant of the follwing MatrixFactorization class.\n",
    "2. Choose Gradient Descent(GD, as default) or Alternating Least Square(ALS) in the parameter setting\n",
    "3. After instantiating the instant, the user can call the train_n_times() method of the object to train the model. \n",
    "'''\n",
    "class MatrixFactorization():\n",
    "    def __init__( self, R=ratings, df=df_ratings, K=20, lr=0.001, rp=0.01, itr= 3, nfolds=5, method='GD', draw=False, threshold=0): \n",
    "        \"\"\"\n",
    "        Arguments/Hyperparamters\n",
    "        -R: user-movie: rating matrix\n",
    "        -K: number of latent dimensions of user & movie vectors\n",
    "        -lr: learning rate\n",
    "        -rp: regularization parametre\n",
    "        -itr: number of iterations\n",
    "        -df: dataframe of three columns: user, movie and rating\n",
    "        -method: GD or ALS\n",
    "        \"\"\"     \n",
    "        self.R=R\n",
    "        self.df = df\n",
    "        self.num_users, self.num_movies = R.shape\n",
    "        self.K = K\n",
    "        self.lr = lr\n",
    "        self.rp = rp\n",
    "        self.itr = itr\n",
    "        self.nfolds = nfolds\n",
    "        self.method = method\n",
    "        self.draw=draw\n",
    "        self.threshold = threshold\n",
    "              \n",
    "    def train_n_times(self):\n",
    "        # set up the empty result list\n",
    "        err=[]\n",
    "        kf = KFold(n_splits= self.nfolds, shuffle=True)\n",
    "        n_t = 1\n",
    "        for train_index, test_index in kf.split(self.df):\n",
    "            print('Training No.', n_t)\n",
    "            n_t += 1\n",
    "            training_set, test_set = self.df.iloc[train_index], self.df.iloc[test_index]\n",
    "            self.check_matrix = np.zeros(self.R.shape)\n",
    "            training_process = self.train(training_set, test_set)\n",
    "            err.append(training_process )\n",
    "        return (err)\n",
    "            \n",
    "    def gradient_descent(self, training):\n",
    "        #Update the parametres of user&movie matrix in one iteration\n",
    "        for u, m, r in training:\n",
    "                error = self.R[u][m] - self.predict_um(u,m)\n",
    "                self.U[u] += self.lr*(error*self.M[m]-self.rp*self.U[u])\n",
    "                self.M[m] += self.lr*(error*self.U[u] - self.rp*self.M[m])\n",
    "    \n",
    "    def ALS(self, training):\n",
    "        #Update the parametres of user&movie matrix in one iteration\n",
    "        r_mat= np.zeros((self.num_users , self.num_movies))\n",
    "        for u, m, r in training:\n",
    "            r_mat[u][m] = r\n",
    "        self.U[:,0] = np.mean(r_mat, axis = 1)\n",
    "        self.M[:,0] = np.mean(r_mat, axis = 0)\n",
    "        \n",
    "        for u in range(self.num_users):\n",
    "            vec = r_mat[u,:].nonzero()[0]\n",
    "            MI = self.M[vec,:]\n",
    "            n = max(len(vec),1)\n",
    "            A = np.dot(MI.T,MI) + self.rp*n*np.eye(self.K)\n",
    "            V = np.dot(MI.T,r_mat[u,vec])\n",
    "            self.U[u,:] = np.linalg.solve(A,V)\n",
    "\n",
    "        for m in range(self.num_movies):\n",
    "            vec = r_mat[:,m].nonzero()[0]\n",
    "            UI = self.U[vec,:]\n",
    "            n = max(len(vec),1)\n",
    "            A = np.dot(UI.T,UI) + self.rp*n*np.eye(self.K)\n",
    "            V = np.dot(UI.T,r_mat[vec,m])\n",
    "            self.M[m,:] = np.linalg.solve(A,V)\n",
    "\n",
    "    def train(self, training_set, test_set):\n",
    "        #Initialize user & movie matrices \n",
    "        np.random.seed(2019)\n",
    "        self.U = np.random.normal(scale=1./self.K, size=(self.num_users, self.K))\n",
    "        np.random.seed(2019)\n",
    "        self.M = np.random.normal(scale=1./self.K, size=(self.num_movies, self.K))\n",
    "        #Begin the training\n",
    "        training_process = []\n",
    "        training = training_set.as_matrix().astype(int)\n",
    "        test = test_set.as_matrix().astype(int)\n",
    "        for i in range(self.itr):\n",
    "            if self.method == 'GD':\n",
    "                self.gradient_descent(training)\n",
    "            elif self.method == 'ALS':\n",
    "                self.ALS(training)\n",
    "            else:\n",
    "                sys.exit(\"Oops! Use GD or ALS as your method\")\n",
    "            mse_training = self.calculate_mse(training)\n",
    "            mse_test = self.calculate_mse(test, mode=\"test\")\n",
    "            training_process.append((i, mse_training, mse_test))        \n",
    "            print(\"Iteration: %d; mse_traing: %.4f; mse_test: %.4f\"%(i+1, mse_training, mse_test))\n",
    "            if mse_training <= self.threshold:\n",
    "                break\n",
    "        if self.draw==True:\n",
    "            self.drawplot(training_process)\n",
    "        return training_process\n",
    "                    \n",
    "    def drawplot(self,training_process):\n",
    "        iterations = [i for i, mse_training, mse_test in training_process]\n",
    "        mse_training = [mse_training for i, mse_training, mse_test in training_process]\n",
    "        mse_test = [mse_test for i, mse_training, mse_test in training_process]\n",
    "        plt.figure(figsize=(16, 4))\n",
    "        plt.title(\"Training Error And Validation Error\")\n",
    "        plt.plot(iterations, mse_training, color='blue', label = 'training error')\n",
    "        plt.plot(iterations, mse_test, color='orange', label='validation error')\n",
    "        plt.xticks(iterations, iterations)\n",
    "        plt.xlabel(\"Iterations\")\n",
    "        plt.ylabel(\"Mean Square Error\")\n",
    "        plt.legend()\n",
    "        plt.grid(axis=\"y\")\n",
    "        plt.show()\n",
    "   \n",
    "    def round_of_rating(self, R):\n",
    "        R[np.where(R<1)] = 1\n",
    "        R[np.where(R>5)] = 5     \n",
    "        return R\n",
    "    \n",
    "    def predictAll(self):\n",
    "        #Predict All the Ratings, return a full rating matrix\n",
    "        predictions = self.U.dot(self.M.T)\n",
    "        return self.round_of_rating(predictions)       \n",
    "    \n",
    "    def predict_um(self, u, m, mode=\"train\"):\n",
    "        #Predict the rating of user u to movie m        \n",
    "        if mode==\"test\":\n",
    "            if np.count_nonzero(self.check_matrix[u])==0 or np.count_nonzero(self.check_matrix.T[m])==0:\n",
    "               #userId or movieId not present in training_set  -> avoid Data Leakage              \n",
    "                   return self.check_matrix.mean()\n",
    "            return self.U[u,:].dot(self.M[m].T)\n",
    "       \n",
    "        prediction = self.U[u,:].dot(self.M[m].T)\n",
    "        self.check_matrix[u][m]=prediction\n",
    "        return prediction\n",
    "    \n",
    "    def calculate_mse(self, d, mode=\"train\"):\n",
    "        #Calculate mse for Training/Testing set\n",
    "        #train_pred['diff'] = (d.rating - self.predictALL))**2\n",
    "        #err_train.append(np.sqrt(train_pred['diff'].mean()))\n",
    "        num_of_d = len(d)\n",
    "        error = 0\n",
    "        \n",
    "        for i, j, r  in d:\n",
    "            prediction = self.predict_um(i,j, mode)\n",
    "            error += (prediction - self.R[i][j] )**2\n",
    "            \n",
    "        error = error/num_of_d\n",
    "        return error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Optimization\n",
    "In this section we will discuss the methods to find the optimal number of iterations, learning rate and latent factors.\n",
    "\n",
    "- Learning Rate\n",
    "\n",
    "Learning Rate can influence the speed of convergence. A model with a too small learning rate need more time to train and might be trapped in local optimum while too large learning rate can cause the model to miss the optimum. \n",
    "<br> In this experiment we try several learning rate and choose the one which uses minimal iterations to reach a particular mse.\n",
    "\n",
    "- Number of Latent Factors\n",
    "\n",
    "The number of **latent factors** determines the amount of abstract information that we want to store in a lower dimension space.[1]\n",
    "<br>We searched some optimization methods and there are several methods for determining the number of factors, such as Minimum Average Partial Method(MAP)[2] , Cattell's Scree Test[3] , K1-Kaiser Method[4] et al.\n",
    "\n",
    "- Number of Iterations\n",
    "\n",
    "Too few iterations can lead to underfitting and too many can lead to overfitting. To find the optimal number of iterations, we need to monitor the value of cross-validation error during the training process. If the cross-validation error decreases with number of iterations increasing, we can improve the performance of the model by increasing iterations. If the cross-validation error starts to increase with the increasing of iterations, we should stop training the model. Therefore, the corresponding iteration of the minimal mse on test set during the process is considered as the optimal number of iterations(NOI). In the case of 5-Fold Cross Validation, we will find the optimal NOIs on 5 models and if one of them reaches the majority, i.e. 3 of 5, we will use this number as the optimal NOI of the model. If none of them reaches the majority, we will consider the second best NOI of the models and so on.\n",
    "\n",
    "We fine tuned the parameters based on how well the model decreased the MSE. We did not using early stopping when we spotted overfitting because it simultaneously affect how well it fits training set and validation set(not orthogonalized).\n",
    "\n",
    "For example, we fine tuned the number of iteration for GD when MSE for test data stopped decreasing. The figure below illustrates one of the steps during the optimization.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Original Dataset](./figures/lr0.006rp0.01GD1.png)\n",
    "<center>figure (a) Fold 1</center>\n",
    "![Original Dataset](./figures/lr0.006rp0.01GD2.png)\n",
    "<center>figure (b) Fold 2</center>\n",
    "![Original Dataset](./figures/lr0.006rp0.01GD3.png)\n",
    "<center>figure (c) Fold 3</center>\n",
    "![Original Dataset](./figures/lr0.006rp0.01GD4.png)\n",
    "<center>figure (d) Fold 4</center>\n",
    "![Original Dataset](./figures/lr0.006rp0.01GD5.png)\n",
    "<center>figure (e) Fold 5</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following table we listed the minimal mse of test set of each model and its corresponding optimal number of  iterations.\n",
    "\n",
    "\n",
    "| Fold | Fold1 | Fold2 | Fold3 | Fold4 | Fold5 |\n",
    "| --- | --- | --- | --- | --- | --- |\n",
    "| opt_itr |27|26|26|26|27|\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment & Result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training No. 1\n",
      "Iteration: 1; mse_traing: 14.0708; mse_test: 14.0650\n",
      "Iteration: 2; mse_traing: 13.9749; mse_test: 13.9745\n",
      "Iteration: 3; mse_traing: 12.3952; mse_test: 12.4178\n",
      "Iteration: 4; mse_traing: 6.5726; mse_test: 6.6303\n",
      "Iteration: 5; mse_traing: 3.4394; mse_test: 3.4952\n",
      "Iteration: 6; mse_traing: 2.2705; mse_test: 2.3208\n",
      "Iteration: 7; mse_traing: 1.7322; mse_test: 1.7777\n",
      "Iteration: 8; mse_traing: 1.4428; mse_test: 1.4846\n",
      "Iteration: 9; mse_traing: 1.2696; mse_test: 1.3085\n",
      "Iteration: 10; mse_traing: 1.1576; mse_test: 1.1945\n",
      "Iteration: 11; mse_traing: 1.0812; mse_test: 1.1166\n",
      "Iteration: 12; mse_traing: 1.0267; mse_test: 1.0611\n",
      "Iteration: 13; mse_traing: 0.9865; mse_test: 1.0201\n",
      "Iteration: 14; mse_traing: 0.9561; mse_test: 0.9892\n",
      "Iteration: 15; mse_traing: 0.9324; mse_test: 0.9652\n",
      "Iteration: 16; mse_traing: 0.9136; mse_test: 0.9462\n",
      "Iteration: 17; mse_traing: 0.8985; mse_test: 0.9310\n",
      "Iteration: 18; mse_traing: 0.8860; mse_test: 0.9185\n",
      "Iteration: 19; mse_traing: 0.8756; mse_test: 0.9081\n",
      "Iteration: 20; mse_traing: 0.8667; mse_test: 0.8994\n",
      "Iteration: 21; mse_traing: 0.8591; mse_test: 0.8920\n",
      "Iteration: 22; mse_traing: 0.8524; mse_test: 0.8855\n",
      "Iteration: 23; mse_traing: 0.8464; mse_test: 0.8798\n",
      "Iteration: 24; mse_traing: 0.8411; mse_test: 0.8747\n",
      "Iteration: 25; mse_traing: 0.8361; mse_test: 0.8701\n",
      "Iteration: 26; mse_traing: 0.8315; mse_test: 0.8659\n",
      "Iteration: 27; mse_traing: 0.8272; mse_test: 0.8620\n",
      "Iteration: 28; mse_traing: 0.8231; mse_test: 0.8584\n",
      "Training No. 2\n",
      "Iteration: 1; mse_traing: 14.0632; mse_test: 14.0959\n",
      "Iteration: 2; mse_traing: 13.9690; mse_test: 14.0063\n",
      "Iteration: 3; mse_traing: 12.4127; mse_test: 12.4668\n",
      "Iteration: 4; mse_traing: 6.5984; mse_test: 6.6784\n",
      "Iteration: 5; mse_traing: 3.4449; mse_test: 3.5249\n",
      "Iteration: 6; mse_traing: 2.2738; mse_test: 2.3415\n",
      "Iteration: 7; mse_traing: 1.7342; mse_test: 1.7923\n",
      "Iteration: 8; mse_traing: 1.4440; mse_test: 1.4956\n",
      "Iteration: 9; mse_traing: 1.2704; mse_test: 1.3174\n",
      "Iteration: 10; mse_traing: 1.1583; mse_test: 1.2020\n",
      "Iteration: 11; mse_traing: 1.0819; mse_test: 1.1229\n",
      "Iteration: 12; mse_traing: 1.0275; mse_test: 1.0663\n",
      "Iteration: 13; mse_traing: 0.9874; mse_test: 1.0245\n",
      "Iteration: 14; mse_traing: 0.9570; mse_test: 0.9927\n",
      "Iteration: 15; mse_traing: 0.9334; mse_test: 0.9680\n",
      "Iteration: 16; mse_traing: 0.9146; mse_test: 0.9484\n",
      "Iteration: 17; mse_traing: 0.8995; mse_test: 0.9326\n",
      "Iteration: 18; mse_traing: 0.8871; mse_test: 0.9196\n",
      "Iteration: 19; mse_traing: 0.8766; mse_test: 0.9088\n",
      "Iteration: 20; mse_traing: 0.8678; mse_test: 0.8997\n",
      "Iteration: 21; mse_traing: 0.8602; mse_test: 0.8919\n",
      "Iteration: 22; mse_traing: 0.8535; mse_test: 0.8851\n",
      "Iteration: 23; mse_traing: 0.8475; mse_test: 0.8792\n",
      "Iteration: 24; mse_traing: 0.8421; mse_test: 0.8739\n",
      "Iteration: 25; mse_traing: 0.8372; mse_test: 0.8692\n",
      "Iteration: 26; mse_traing: 0.8325; mse_test: 0.8648\n",
      "Iteration: 27; mse_traing: 0.8282; mse_test: 0.8608\n",
      "Iteration: 28; mse_traing: 0.8240; mse_test: 0.8570\n",
      "Training No. 3\n",
      "Iteration: 1; mse_traing: 14.0738; mse_test: 14.0536\n",
      "Iteration: 2; mse_traing: 13.9790; mse_test: 13.9639\n",
      "Iteration: 3; mse_traing: 12.4132; mse_test: 12.4211\n",
      "Iteration: 4; mse_traing: 6.5974; mse_test: 6.6329\n",
      "Iteration: 5; mse_traing: 3.4479; mse_test: 3.4885\n",
      "Iteration: 6; mse_traing: 2.2746; mse_test: 2.3160\n",
      "Iteration: 7; mse_traing: 1.7346; mse_test: 1.7739\n",
      "Iteration: 8; mse_traing: 1.4446; mse_test: 1.4813\n",
      "Iteration: 9; mse_traing: 1.2711; mse_test: 1.3054\n",
      "Iteration: 10; mse_traing: 1.1592; mse_test: 1.1915\n",
      "Iteration: 11; mse_traing: 1.0828; mse_test: 1.1134\n",
      "Iteration: 12; mse_traing: 1.0283; mse_test: 1.0577\n",
      "Iteration: 13; mse_traing: 0.9882; mse_test: 1.0166\n",
      "Iteration: 14; mse_traing: 0.9578; mse_test: 0.9854\n",
      "Iteration: 15; mse_traing: 0.9342; mse_test: 0.9612\n",
      "Iteration: 16; mse_traing: 0.9155; mse_test: 0.9420\n",
      "Iteration: 17; mse_traing: 0.9004; mse_test: 0.9265\n",
      "Iteration: 18; mse_traing: 0.8880; mse_test: 0.9138\n",
      "Iteration: 19; mse_traing: 0.8777; mse_test: 0.9033\n",
      "Iteration: 20; mse_traing: 0.8689; mse_test: 0.8944\n",
      "Iteration: 21; mse_traing: 0.8613; mse_test: 0.8868\n",
      "Iteration: 22; mse_traing: 0.8546; mse_test: 0.8802\n",
      "Iteration: 23; mse_traing: 0.8487; mse_test: 0.8744\n",
      "Iteration: 24; mse_traing: 0.8434; mse_test: 0.8692\n",
      "Iteration: 25; mse_traing: 0.8385; mse_test: 0.8645\n",
      "Iteration: 26; mse_traing: 0.8339; mse_test: 0.8603\n",
      "Iteration: 27; mse_traing: 0.8297; mse_test: 0.8563\n",
      "Iteration: 28; mse_traing: 0.8256; mse_test: 0.8526\n",
      "Training No. 4\n",
      "Iteration: 1; mse_traing: 14.0657; mse_test: 14.0857\n",
      "Iteration: 2; mse_traing: 13.9704; mse_test: 13.9949\n",
      "Iteration: 3; mse_traing: 12.3967; mse_test: 12.4375\n",
      "Iteration: 4; mse_traing: 6.5728; mse_test: 6.6402\n",
      "Iteration: 5; mse_traing: 3.4374; mse_test: 3.4968\n",
      "Iteration: 6; mse_traing: 2.2696; mse_test: 2.3221\n",
      "Iteration: 7; mse_traing: 1.7315; mse_test: 1.7792\n",
      "Iteration: 8; mse_traing: 1.4422; mse_test: 1.4863\n",
      "Iteration: 9; mse_traing: 1.2691; mse_test: 1.3104\n",
      "Iteration: 10; mse_traing: 1.1574; mse_test: 1.1965\n",
      "Iteration: 11; mse_traing: 1.0811; mse_test: 1.1185\n",
      "Iteration: 12; mse_traing: 1.0267; mse_test: 1.0628\n",
      "Iteration: 13; mse_traing: 0.9867; mse_test: 1.0216\n",
      "Iteration: 14; mse_traing: 0.9563; mse_test: 0.9904\n",
      "Iteration: 15; mse_traing: 0.9328; mse_test: 0.9662\n",
      "Iteration: 16; mse_traing: 0.9141; mse_test: 0.9470\n",
      "Iteration: 17; mse_traing: 0.8989; mse_test: 0.9315\n",
      "Iteration: 18; mse_traing: 0.8865; mse_test: 0.9188\n",
      "Iteration: 19; mse_traing: 0.8761; mse_test: 0.9082\n",
      "Iteration: 20; mse_traing: 0.8672; mse_test: 0.8993\n",
      "Iteration: 21; mse_traing: 0.8596; mse_test: 0.8916\n",
      "Iteration: 22; mse_traing: 0.8529; mse_test: 0.8850\n",
      "Iteration: 23; mse_traing: 0.8469; mse_test: 0.8792\n",
      "Iteration: 24; mse_traing: 0.8415; mse_test: 0.8740\n",
      "Iteration: 25; mse_traing: 0.8366; mse_test: 0.8693\n",
      "Iteration: 26; mse_traing: 0.8320; mse_test: 0.8650\n",
      "Iteration: 27; mse_traing: 0.8276; mse_test: 0.8611\n",
      "Iteration: 28; mse_traing: 0.8234; mse_test: 0.8573\n",
      "Training No. 5\n",
      "Iteration: 1; mse_traing: 14.0712; mse_test: 14.0635\n",
      "Iteration: 2; mse_traing: 13.9763; mse_test: 13.9732\n",
      "Iteration: 3; mse_traing: 12.4081; mse_test: 12.4205\n",
      "Iteration: 4; mse_traing: 6.5877; mse_test: 6.6302\n",
      "Iteration: 5; mse_traing: 3.4475; mse_test: 3.4875\n",
      "Iteration: 6; mse_traing: 2.2747; mse_test: 2.3132\n",
      "Iteration: 7; mse_traing: 1.7343; mse_test: 1.7715\n",
      "Iteration: 8; mse_traing: 1.4439; mse_test: 1.4799\n",
      "Iteration: 9; mse_traing: 1.2702; mse_test: 1.3051\n",
      "Iteration: 10; mse_traing: 1.1581; mse_test: 1.1919\n",
      "Iteration: 11; mse_traing: 1.0817; mse_test: 1.1146\n",
      "Iteration: 12; mse_traing: 1.0272; mse_test: 1.0594\n",
      "Iteration: 13; mse_traing: 0.9870; mse_test: 1.0186\n",
      "Iteration: 14; mse_traing: 0.9566; mse_test: 0.9878\n",
      "Iteration: 15; mse_traing: 0.9330; mse_test: 0.9638\n",
      "Iteration: 16; mse_traing: 0.9142; mse_test: 0.9449\n",
      "Iteration: 17; mse_traing: 0.8991; mse_test: 0.9297\n",
      "Iteration: 18; mse_traing: 0.8867; mse_test: 0.9172\n",
      "Iteration: 19; mse_traing: 0.8763; mse_test: 0.9068\n",
      "Iteration: 20; mse_traing: 0.8674; mse_test: 0.8981\n",
      "Iteration: 21; mse_traing: 0.8598; mse_test: 0.8907\n",
      "Iteration: 22; mse_traing: 0.8531; mse_test: 0.8842\n",
      "Iteration: 23; mse_traing: 0.8472; mse_test: 0.8786\n",
      "Iteration: 24; mse_traing: 0.8418; mse_test: 0.8735\n",
      "Iteration: 25; mse_traing: 0.8369; mse_test: 0.8690\n",
      "Iteration: 26; mse_traing: 0.8324; mse_test: 0.8648\n",
      "Iteration: 27; mse_traing: 0.8281; mse_test: 0.8609\n",
      "Iteration: 28; mse_traing: 0.8240; mse_test: 0.8573\n"
     ]
    }
   ],
   "source": [
    "# Use Gradient Descent as Optimization Method\n",
    "mf = MatrixFactorization(itr=28,K=15)\n",
    "err = mf.train_n_times() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training No. 1\n",
      "Iteration: 1; mse_traing: 0.8495; mse_test: 0.8964\n",
      "Iteration: 2; mse_traing: 0.7406; mse_test: 0.8353\n",
      "Iteration: 3; mse_traing: 0.6751; mse_test: 0.7843\n",
      "Iteration: 4; mse_traing: 0.6556; mse_test: 0.7610\n",
      "Training No. 2\n",
      "Iteration: 1; mse_traing: 0.8507; mse_test: 0.8941\n",
      "Iteration: 2; mse_traing: 0.7398; mse_test: 0.8325\n",
      "Iteration: 3; mse_traing: 0.6754; mse_test: 0.7844\n",
      "Iteration: 4; mse_traing: 0.6565; mse_test: 0.7619\n",
      "Training No. 3\n",
      "Iteration: 1; mse_traing: 0.8512; mse_test: 0.8891\n",
      "Iteration: 2; mse_traing: 0.7414; mse_test: 0.8300\n",
      "Iteration: 3; mse_traing: 0.6769; mse_test: 0.7818\n",
      "Iteration: 4; mse_traing: 0.6575; mse_test: 0.7575\n",
      "Training No. 4\n",
      "Iteration: 1; mse_traing: 0.8512; mse_test: 0.8947\n",
      "Iteration: 2; mse_traing: 0.7396; mse_test: 0.8348\n",
      "Iteration: 3; mse_traing: 0.6756; mse_test: 0.7877\n",
      "Iteration: 4; mse_traing: 0.6562; mse_test: 0.7629\n",
      "Training No. 5\n",
      "Iteration: 1; mse_traing: 0.8499; mse_test: 0.8931\n",
      "Iteration: 2; mse_traing: 0.7393; mse_test: 0.8297\n",
      "Iteration: 3; mse_traing: 0.6762; mse_test: 0.7815\n",
      "Iteration: 4; mse_traing: 0.6571; mse_test: 0.7576\n"
     ]
    }
   ],
   "source": [
    "# Use ALS as Optimization Method\n",
    "mf2 = MatrixFactorization(itr=4, method='ALS', rp = 0.1)\n",
    "err2 = mf2.train_n_times() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For the MF with GD \n",
      "Mean error on TRAIN: 0.8240212466645703\n",
      "Mean error on  TEST: 0.856515249373324\n",
      "For the MF with ALS \n",
      "Mean error on TRAIN: 0.656587043554242\n",
      "Mean error on  TEST: 0.7601634389623356\n"
     ]
    }
   ],
   "source": [
    "#print the final results\n",
    "result1 = np.mean(err, axis=0)[-1]\n",
    "result2 = np.mean(err2, axis=0)[-1]\n",
    "print(\"For the MF with GD \")\n",
    "print(\"Mean error on TRAIN: \" + str(result1[1])) #Mean Error on Training set\n",
    "print(\"Mean error on  TEST: \" + str(result1[2])) #Mean Error on Test set\n",
    "print(\"For the MF with ALS \")\n",
    "print(\"Mean error on TRAIN: \" + str(result2[1])) #Mean Error on Training set\n",
    "print(\"Mean error on  TEST: \" + str(result2[2])) #Mean Error on Test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results\n",
    "### MSE\n",
    "The result shows that Matrix Factorization has better results than naive linear regression. \n",
    "\n",
    "### Gradient Descent VS ALS\n",
    "The ALS method converges much faster than Gradient Descent. \n",
    "\n",
    "### Overfitting\n",
    "The mse on test set is much larger than that on training set, which means there is overfitting. We can further increase the value of regularization parametre(rp) or decrease the number of latent factors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Reference\n",
    "\n",
    "[1]Liao, Kevin. “Prototyping a Recommender System Step by Step Part 2: Alternating Least Square (ALS) Matrix Factorization in Collaborative Filtering.” Medium, Towards Data Science, 19 Nov. 2018, https://towardsdatascience.com/prototyping-a-recommender-system-step-by-step-part-2-alternating-least-square-als-matrix-4a76c58714a1.<br>\n",
    "[2]Liao, K. (2018, November 19). Prototyping a Recommender System Step by Step Part 2: Alternating Least Square (ALS) Matrix Factorization in Collaborative Filtering. Retrieved from https://towardsdatascience.com/prototyping-a-recommender-system-step-by-step-part-2-alternating-least-square-als-matrix-4a76c58714a1<br>\n",
    "[3]D'agostino, R. B., & Russell, H. K. (2014, September 29). Scree Test. Retrieved from https://onlinelibrary.wiley.com/doi/abs/10.1002/9781118445112.stat05605<br>\n",
    "[4]Retrieved from https://psycnet.apa.org/fulltext/2016-15750-001.html<br>\n",
    "[5]Retrieved from https://psycnet.apa.org/fulltext/2016-15750-001.html<br>\n",
    "[6]Retrieved from https://psycnet.apa.org/fulltext/2016-15750-001.html<br>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
