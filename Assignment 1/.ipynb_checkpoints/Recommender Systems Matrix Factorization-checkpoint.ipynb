{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recommender Systems  Matrix Factorization \n",
    "## Introduction\n",
    "In this task, we will be working on the MovieLens 1M dataset which can be fetched from moivelens . This set contains about 1.000.000 ratings given to about 4.000 movies by about 6.000 users. Our task adopted Matrix Factorization Algorithm in Python and estimated the accuracy with the Root Mean Squared Error, RMSE, and the Mean Absolute Error, MAE.\n",
    "\n",
    "To make sure that the results are reliable, 5-fold cross- validation is used.\n",
    "\n",
    "## Gradient Descend\n",
    "This was described in the paper gravity-Tikk.pdf (the beginning of section 3.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import random\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "from math import sqrt\n",
    "\n",
    "#Import libs to plot the training process\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#Set the random seed to make the experiment repeatable\n",
    "np.random.seed(2019)\n",
    "random.seed(2019)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data\n",
    "The CSV file ratings.csv contains 100836 ratings created by 610 users about 9742 movies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Define the file path\n",
    "file_path = '../data/ratings.csv'#\"./ml-latest-small/ratings.csv\" \n",
    "df_ratings = pd.read_csv(file_path, header=0, names=['userId', 'movieId', 'rating'], index_col=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Renumbering user and movie IDs\n",
    "uniqueMovieIds = df_ratings.movieId.unique() #Obtain the unique movie Ids\n",
    "uniqueUserIds = df_ratings.userId.unique() #Obtain the unique user Ids\n",
    "\n",
    "#Create New movieIds according to unique movie Ids\n",
    "newMovieIds = [np.where(uniqueMovieIds==x)[0][0] for x in df_ratings['movieId'].tolist()]\n",
    "newMovieIds = np.array(newMovieIds)\n",
    "\n",
    "#Create New userIds according to unique user Ids\n",
    "newUserIds = [np.where(uniqueUserIds==x)[0][0] for x in df_ratings['userId'].tolist()]\n",
    "newUserIds = np.array(newUserIds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Add new movieIds and new userIds to the dataframe\n",
    "df_ratings['newMovieId'] = newMovieIds\n",
    "df_ratings['newUserId'] = newUserIds\n",
    "\n",
    "#Reconstruct the dataframe\n",
    "df_ratings = df_ratings[[\"newUserId\",\"newMovieId\",\"rating\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(610, 9724)\n"
     ]
    }
   ],
   "source": [
    "#Construct The Rating Matrix acorting to the new ids\n",
    "num_users = df_ratings['newUserId'].max()+1  #There are 610 users\n",
    "num_movies = df_ratings['newMovieId'].max()+1 #The Max Value of movieId\n",
    "\n",
    "ratings = np.zeros((num_users , num_movies))\n",
    "\n",
    "print(ratings.shape)\n",
    "\n",
    "for i in range(df_ratings.shape[0]):\n",
    "    ratings[df_ratings.loc[i, 'newUserId']][df_ratings.loc[i,'newMovieId']] = df_ratings.loc[i, 'rating']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class MatrixFactorization():\n",
    "    def __init__( self, R=ratings, df=df_ratings, K=20, lr=0.001, rp=0.01, itr= 3, nfolds=5): \n",
    "        #change itr and set thresholds\n",
    "        \"\"\"\n",
    "        Arguments/Hyperparamters\n",
    "        -R: user-movie: rating matrix\n",
    "        -K: number of latent dimensions of user & movie vectors\n",
    "        -lr: learning rate\n",
    "        -rp: regularization parametre\n",
    "        -itr: number of iterations\n",
    "        \"\"\"     \n",
    "        self.R=R\n",
    "        self.df = df\n",
    "        self.num_users, self.num_movies = R.shape\n",
    "        self.K = K\n",
    "        self.lr = lr\n",
    "        self.rp = rp\n",
    "        self.itr = itr\n",
    "        self.nfolds = nfolds\n",
    "              \n",
    "    def train_n_times(self):\n",
    "        # set up the empty result list\n",
    "        err=[]\n",
    "        kf = KFold(n_splits= self.nfolds, shuffle=True)\n",
    "        n_t = 1\n",
    "        for train_index, test_index in kf.split(self.df):\n",
    "            print('Training No.', n_t)\n",
    "            n_t += 1\n",
    "            training_set, test_set = self.df.iloc[train_index], self.df.iloc[test_index]\n",
    "            training_process = self.train(training_set, test_set)\n",
    "            err.append(training_process )\n",
    "        return (err)\n",
    "            \n",
    "    def gradient_descent(self, training):\n",
    "        #Update the parametres of user&movie matrix in one iteration\n",
    "        for u, m, r in training:\n",
    "            if r:\n",
    "                error = r - self.predict_um(u,m)\n",
    "                self.U[u] += self.lr*(error*self.M[m]-self.rp*self.U[u])\n",
    "                self.M[m] += self.lr*(error*self.U[u] - self.rp*self.M[m])\n",
    "\n",
    "    def train(self, training_set, test_set):\n",
    "        #Initialize user & movie matrices \n",
    "        self.U = np.random.normal(scale=1./self.K, size=(self.num_users, self.K))\n",
    "        self.M = np.random.normal(scale=1./self.K, size=(self.num_movies, self.K))\n",
    "        \n",
    "        #Perform stochastic gradient descent \n",
    "        training_process = []\n",
    "        training = training_set.as_matrix().astype(int)\n",
    "        test = test_set.as_matrix().astype(int)\n",
    "        for i in range(self.itr):\n",
    "            self.gradient_descent(training)\n",
    "            mse_training = self.calculate_mse(training)\n",
    "            mse_test = self.calculate_mse(test)\n",
    "            training_process.append((i, mse_training, mse_test))\n",
    "        \n",
    "            print(\"Iteration: %d; mse_traing: %.4f; mse_test: %.4f\"%(i+1, mse_training, mse_test))\n",
    "            \n",
    "        iterations = [i for i, mse_training, mse_test in training_process]\n",
    "        mse_training = [mse_training for i, mse_training, mse_test in training_process]\n",
    "        mse_test = [mse_test for i, mse_training, mse_test in training_process]\n",
    "        plt.figure(figsize=(16, 4))\n",
    "        plt.title(\"Training Error And Validation Error\")\n",
    "        plt.plot(iterations, mse_training, color='blue', label = 'training error')\n",
    "        plt.plot(iterations, mse_test, color='orange', label='validation error')\n",
    "        plt.xticks(iterations, iterations)\n",
    "        plt.xlabel(\"Iterations\")\n",
    "        plt.ylabel(\"Mean Square Error\")\n",
    "        plt.legend()\n",
    "        plt.grid(axis=\"y\")\n",
    "        #plt.show()\n",
    "        return training_process\n",
    "            \n",
    "            \n",
    "    def round_of_rating(self, R):\n",
    "        matrixRound = np.vectorize(round) #Vectorize the round function\n",
    "        return matrixRound(R*2)/2 # Round off the rating to nearest 0.5\n",
    "    \n",
    "    \n",
    "    def predictAll(self):\n",
    "        #Predict All the Ratings, return a full rating matrix\n",
    "        predictions = self.U.dot(self.M.T)\n",
    "        return self.round_of_rating(predictions)       \n",
    "    \n",
    "    def predict_um(self, u, m):\n",
    "        #Predict the rating of user u to movie m\n",
    "        prediction = self.U[u,:].dot(self.M[m].T)\n",
    "        return prediction\n",
    "    \n",
    "    def calculate_mse(self, d):\n",
    "        #Calculate mse for Training/Testing set\n",
    "        #train_pred['diff'] = (d.rating - self.predictALL))**2\n",
    "        #err_train.append(np.sqrt(train_pred['diff'].mean()))\n",
    "        num_of_d = len(d)\n",
    "        error = 0\n",
    "        \n",
    "        for i, j, r in d:\n",
    "            prediction = self.predict_um(i,j)\n",
    "            error += (prediction - r )**2\n",
    "            \n",
    "        error = error/num_of_d\n",
    "        return error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training No. 1\n",
      "Iteration: 1; mse_traing: 12.4048; mse_test: 12.4435\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-239-be62b48b3221>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMatrixFactorization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0merr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_n_times\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-202-280a5e4f28d1>\u001b[0m in \u001b[0;36mtrain_n_times\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     28\u001b[0m             \u001b[0mn_t\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m             \u001b[0mtraining_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_set\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m             \u001b[0mtraining_process\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_set\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m             \u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_process\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-202-280a5e4f28d1>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, training_set, test_set)\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_set\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient_descent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m             \u001b[0mmse_training\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalculate_mse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0mmse_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalculate_mse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-202-280a5e4f28d1>\u001b[0m in \u001b[0;36mgradient_descent\u001b[0;34m(self, training)\u001b[0m\n\u001b[1;32m     37\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m                 \u001b[0merror\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mr\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_um\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mu\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mU\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mu\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mM\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrp\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mU\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mu\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mM\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mU\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mu\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrp\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mM\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "mf = MatrixFactorization()\n",
    "err = mf.train_n_times()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[(0, 12.400866423883944, 12.458552927438825),\n",
       "  (1, 12.397691333876306, 12.457915461740132),\n",
       "  (2, 12.393209249923883, 12.456109685562543)],\n",
       " [(0, 12.414368575944138, 12.403381906529853),\n",
       "  (1, 12.411020019875348, 12.402630602271573),\n",
       "  (2, 12.406137326369773, 12.40046142487515)],\n",
       " [(0, 12.401611440352163, 12.455829307251014),\n",
       "  (1, 12.398713945853055, 12.455397420656423),\n",
       "  (2, 12.394861416286737, 12.454062511976229)],\n",
       " [(0, 12.410941040542369, 12.41739103746136),\n",
       "  (1, 12.407636063735653, 12.416662712916903),\n",
       "  (2, 12.402890045202161, 12.41464182692429)],\n",
       " [(0, 12.431613185070495, 12.337056109916707),\n",
       "  (1, 12.428642235921593, 12.336615012113691),\n",
       "  (2, 12.424555316364138, 12.335177349952641)]]"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result = np.mean(err, axis = 0)[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For the MF with GD \n",
      "Mean error on TRAIN: 12.40499678832716\n",
      "Mean error on  TEST: 12.412558218023136\n"
     ]
    }
   ],
   "source": [
    "#print the final conclusion:\n",
    "print(\"For the MF with GD \")\n",
    "print(\"Mean error on TRAIN: \" + str(result[1]))\n",
    "print(\"Mean error on  TEST: \" + str(result[2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## MF with ALS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "r_mat = df_ratings.pivot(index='userId', columns = 'movieId', values = 'rating')\n",
    "\n",
    "U[:,0] = np.mean(r_mat, axis = 1)\n",
    "M[:,0] = np.mean(r_mat, axis = 0)\n",
    "\n",
    "UI = U[:,X[:,j].nonzero()[0]]\n",
    "\n",
    "for u in range(num_users):\n",
    "    vec = X[u,:].nonzero()[0]\n",
    "    MI = M[vec,:]\n",
    "    n = max(len(vec),1)\n",
    "    A = np.dot(MI.T,MI) + lmda*n*np.eye(num_features)\n",
    "    V = np.dot(MI.T,X[u,X[u,:].nonzero()[0]])\n",
    "    U[u,:] = np.linalg.solve(A,V)\n",
    "        \n",
    "for m in range(num_movies):\n",
    "    vec = X[:,m].nonzero()[0]\n",
    "    UI = U[vec,:]\n",
    "    n = max(len(vec),1)\n",
    "    A = np.dot(UI.T,UI) + lmda*n*np.eye(num_features)\n",
    "    V = np.dot(UI.T,X[X[:,m].nonzero()[0],j])\n",
    "    M[m,:] = np.linalg.solve(A,V)\n",
    "        \n",
    "pred = np.dot(U.T,M)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
